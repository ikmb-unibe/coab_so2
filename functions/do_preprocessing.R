do_preprocessing <- function(dfm) {
  # all to lower
  dfm <- dfm_tolower(dfm)
  # split ngrams
  dfm <- dfm_splitgrams(dfm_replace(dfm, featnames(dfm), gsub(" ", "_", featnames(dfm), fixed = TRUE), case_insensitive = FALSE))
  # removal of features with less than 3 characters
  dfm <- dfm_select(dfm, min_nchar = 3)
  # removal of stopwords
  blacklist.climate <- read.csv("functions/do_preprocessing/blacklist_climate.csv", header = FALSE, quote = "", encoding = 'UTF-8')
  dfm <- dfm_remove(dfm, blacklist.climate$V1, verbose='TRUE')
  stopwords <- read.csv("functions/do_preprocessing/stopwords_en_de.txt", header = FALSE, quote = "", encoding = 'UTF-8')
  dfm <- dfm_remove(dfm, stopwords$V1, verbose='TRUE')
  # stemming (using Martin Porter's stemming algorithm and the C libstemmer library generated by Snowball)
  feat <- featnames(dfm)
  stem <- SnowballC::wordStem(feat, language = "ger")
  dfm <- dfm_replace(dfm, feat, stem, case_insensitive = FALSE)
  dfm <- dfm_compress(dfm, margin = "features")
  # relative pruning (remove features that appear in less than 0.5% and in more than 99% of all documents)
  dfm <- dfm_trim(dfm, min_docfreq = 0.005, max_docfreq = 0.99, docfreq_type = "prop", verbose = TRUE)
  return(dfm)
}
